{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm.auto import tqdm\n",
    "import pebble\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import warnings\n",
    "from scipy.optimize import minimize\n",
    "from concurrent import futures\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"../Code\")\n",
    "\n",
    "# Import model functions\n",
    "from get_current_model import get_model\n",
    "from function_residuals import calculate_residuals, setup_logger\n",
    "from robustness_fit_parameters import get_fitting_parameter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum number of parallel threads and the timeout\n",
    "n_workers = 4 # Maximum number of parallel threads\n",
    "timeout = 300 # Timeout for each thread in seconds\n",
    "\n",
    "# Set the prefix to be used for logging and results files\n",
    "file_prefix = f\"minimise_{datetime.now().strftime('%Y%m%d%H%M')}\"\n",
    "# file_prefix = f\"residuals_test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model to get default parameter values\n",
    "m = get_model(get_y0=False, verbose=False, check_consistency=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitting_startvalue(fitting_parameter, m):\n",
    "    if fitting_parameter == \"fluo_influence\":\n",
    "        return pd.Series({f\"__fluo_influence__{k}\":v for k,v in m.parameters[fitting_parameter].items()})\n",
    "    else:\n",
    "        return pd.Series({fitting_parameter: m.parameters[fitting_parameter]})\n",
    "    \n",
    "def get_fitting_bounds(fitting_parameter, bound, m):\n",
    "    if fitting_parameter == \"fluo_influence\":\n",
    "        return pd.Series({f\"__fluo_influence__{k}\":bound for k in m.parameters[fitting_parameter].keys()})\n",
    "    else:\n",
    "        return pd.Series({fitting_parameter: bound})\n",
    "    \n",
    "def get_fitting_start_and_bounds(fitting_parameters,m):\n",
    "    start_values = [get_fitting_startvalue(x,m) for x in fitting_parameters]\n",
    "    bounds = [get_fitting_bounds(k,v,m) for k,v in fitting_parameters.items()]\n",
    "    return pd.concat(start_values), pd.concat(bounds).values\n",
    "\n",
    "def get_fitting_parameter_dict(values, names):\n",
    "    # Put values into a pandas series for easier handling\n",
    "    res = pd.Series(values, index=names)\n",
    "\n",
    "    # Reconstitute fluo_influence\n",
    "    fluo_influence_bool = res.index.str.startswith(\"__fluo_influence__\")\n",
    "    if fluo_influence_bool.any():\n",
    "        # Extract the intermediate values\n",
    "        _res = res[fluo_influence_bool]\n",
    "        _res.index = _res.index.str.removeprefix(\"__fluo_influence__\")\n",
    "        \n",
    "        res = res[np.invert(fluo_influence_bool)]\n",
    "        res[\"fluo_influence\"] = _res.to_dict()\n",
    "\n",
    "    return res.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting_parameter_bounds = {\n",
    "    \"fluo_influence\": (1e-10,None),\n",
    "    \"lcf\": (1e-10,None),\n",
    "    \"kUnquench\": (1e-10,None),\n",
    "    \"KMUnquench\": (1e-10,None),\n",
    "    \"kQuench\": (1e-10,None),\n",
    "    \"kOCPactivation\": (1e-10,None),\n",
    "    \"kOCPdeactivation\": (1e-10,None),\n",
    "    \"OCPmax\": (1e-10,None),\n",
    "}\n",
    "\n",
    "start_values, bounds = get_fitting_start_and_bounds(fitting_parameter_bounds,m)\n",
    "\n",
    "p, p_names = start_values.values, start_values.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate residuals with arguments tailored to the minimize function\n",
    "def calculate_residuals_minimize(p, p_names, scale_factors=None, file_prefix=\"\"):\n",
    "    # Undo the scaling\n",
    "    if scale_factors is not None:\n",
    "        p = p * scale_factors\n",
    "\n",
    "    _p = get_fitting_parameter_dict(p, p_names)\n",
    "\n",
    "    res = calculate_residuals(\n",
    "        _p,\n",
    "        n_workers=5,\n",
    "        timeout=300, # s\n",
    "        logger_filename=f\"../out/{file_prefix}\",\n",
    "        save_intermediates=False\n",
    "        )\n",
    "\n",
    "    # Save the residuals\n",
    "    with open(Path(f\"../out/{file_prefix}_intermediates.csv\",), \"a\") as f:\n",
    "        f.writelines(f\"{','.join([str(x) for x in p])},{res}\\n\")\n",
    "\n",
    "    return res\n",
    "\n",
    "def scale_bounds(bounds, x0, scale):\n",
    "    # Scale the vector of bounds according to the scaling of the parameters\n",
    "    return [tuple([b*(scale/_x0) if b not in [0,None] else b for b in bound]) for bound, _x0 in zip(bounds, x0)]\n",
    "\n",
    "def fit_model_parameters(start_values, bounds=None, opt_kwargs={}, scale_to_value=None, file_prefix=\"\"):\n",
    "    \n",
    "    # If the parameters should be scaled, replace them with the scaling value\n",
    "    if scale_to_value is None:\n",
    "        p = start_values.values\n",
    "        scale_factors = None\n",
    "    else:\n",
    "        p = np.full(start_values.shape[0], scale_to_value)\n",
    "        scale_factors = start_values.values / scale_to_value\n",
    "        bounds = scale_bounds(bounds, start_values.values, scale_to_value)\n",
    "\n",
    "    if bounds is not None:\n",
    "        opt_kwargs.update({\"bounds\": bounds})\n",
    "\n",
    "    fit = minimize(\n",
    "        fun = calculate_residuals_minimize,\n",
    "        x0 = p,\n",
    "        args = (start_values.index, scale_factors, file_prefix),\n",
    "        **opt_kwargs\n",
    "    )\n",
    "\n",
    "    # Rescale the results\n",
    "    if scale_to_value is not None:\n",
    "        fit.x = fit.x * scale_factors\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def output_model_parameters(start_values, intermediate, bounds=None, opt_kwargs={}, scale_to_value=None, file_prefix=\"\"):\n",
    "    \n",
    "    # If the parameters should be scaled, replace them with the scaling value\n",
    "    if scale_to_value is None:\n",
    "        p = start_values.values\n",
    "        scale_factors = None\n",
    "    else:\n",
    "        p = np.full(start_values.shape[0], scale_to_value)\n",
    "        scale_factors = start_values.values / scale_to_value\n",
    "        bounds = scale_bounds(bounds, start_values.values, scale_to_value)\n",
    "\n",
    "    if bounds is not None:\n",
    "        opt_kwargs.update({\"bounds\": bounds})\n",
    "\n",
    "\n",
    "    res = calculate_residuals_minimize(\n",
    "        intermediate,\n",
    "        start_values.index,\n",
    "        scale_factors,\n",
    "        file_prefix\n",
    "        )\n",
    "\n",
    "    # Rescale the results\n",
    "    if scale_to_value is not None:\n",
    "        res = res * scale_factors\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.read_csv(\"../out/minimise_202405061745_intermediates.csv\", header=None)\n",
    "min_param = out.loc[out[10].idxmin(), :9].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locally optimise the model\n",
    "with warnings.catch_warnings() as w:\n",
    "    # Cause all warnings to always be triggered.\n",
    "    # warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    res = output_model_parameters(\n",
    "        start_values,\n",
    "        intermediate=min_param,\n",
    "        bounds=bounds, \n",
    "        scale_to_value=None, \n",
    "        opt_kwargs={\"method\":\"Nelder-Mead\"},\n",
    "        file_prefix=file_prefix\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_fitting_parameter_dict(min_param, start_values.index)\n",
    "start = get_fitting_parameter_dict(start_values.values, start_values.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locally optimise the model\n",
    "with warnings.catch_warnings() as w:\n",
    "    # Cause all warnings to always be triggered.\n",
    "    # warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fit = fit_model_parameters(\n",
    "        start_values, \n",
    "        bounds=bounds, \n",
    "        scale_to_value=0.01, \n",
    "        opt_kwargs={\"method\":\"Nelder-Mead\"},\n",
    "        file_prefix=file_prefix\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(f\"../Results/{file_prefix}_results.pickle\",), \"wb\") as f:\n",
    "    pickle.dump(fit, f)\n",
    "\n",
    "# with open(Path(f\"../Results/{file_prefix}_results.pickle\",), \"rb\") as f:\n",
    "#     test = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synechocystis-etc-2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
