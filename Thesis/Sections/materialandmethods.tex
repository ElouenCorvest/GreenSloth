\subsection{Models}

To make a good demonstration of the capabilities of \greensloth{}, five kinetic \gls{ode} models of photosynthesis have been chosen to take part in this thesis. These five models, while all showing photosynthesis, vary in their complexity and execution. Some are based on each other, while others stand alone. In the following, a brief description of each model is given. These short summaries are the ones used on the \greensloth{} website. Additionally, the models are validated by trying to recreate the figures of the original publication, as close as possible. Due to permissions and licensing issues, the original figures will not be present in this thesis nor \greensloth{}. However, the publication is rightfully cited and so, the user can easily find the original figures, if they have access to the publication.

\subsubsection{Bellasio2019}
The Bellasio2019~\cite{bellasioGeneralisedDynamicModel2019} model is a generalized C\textsubscript{3} leaf-photosynthesis model, that includes simplified representations of the light and dark reactions and a stomatal behavior submodule. A lot of its implementation is based on past work by the same author and is mainly inspired by the common \gls{fvcb} model. The light reactions are modified from Yin et al. (2004) and include the potential rates of ATP and NADPH production based on light intensity. This model has been created with the simple user in mind, and the author has made an effort to show its simplicity, by giving access to a Microsoft Excel Workbook containing the entire model. To showcase the model's capabilities, the author creates common steady-state carbon assimilation curves, against intercellular CO2 concentration and light intensity, and compares them to experimental data from the literature. As many models of photosynthesis rely on purely stead-state assumptions, this model is also validated in dynamic conditions, showing for example the response of the model to a fluctuation of ambient oxygen concentration.

This model was created to stay as simple as possible, while still being able to accurately represent the main features of C\textsubscript{3} photosynthesis. As such, it can be used as a base for more complex models, or as a starting block in larger models of plant physiology. While giving access to the entire model in an Excel Workbook format is transparent and great, the execution of said practice has been inefficient in this instance. The entire mathematical description of the model is also given in the Appendix of the publication, however there are missing or different equations between the publication and the Excel Workbook, which can lead to confusion. On top of that, the simulation protocols used for each figure are only given in small details, which leads to further confusion when trying to reproduce the results and see which equations are correct or not.

\subsubsection{Fuente2024}
The Fuente2024~\cite{fuenteMathematicalModelSimulate2024} model is a kinetic model of photosynthesis that is based on Occam's razor, aiming to provide the minimal complexity to describe the core processes of this model. In this case, the model focuses on the dynamic light oscillation and its responses on the photosynthetic machinery. It focuses only on the light-dependent reactions, including simplified versions of photosystem II, photosystem I, the Plastoquinone pool, and proton and ATP concentration in the lumen and stroma. On top of that, it shows the activation of non-photochemical quenching (NPQ), the dynamics of chlorophyll fluorescence, and the rate of oxygen evolution.
                     
The model includes the oscillating light intensity as a sinusoidal function, where the amplitude and frequency are adjustable parameters. To allow for easier comparison to other models, that often see light intensity as a constant value, the oscillation is defined around a base light intensity. However, the strength of having light with a specific frequency lies in the additional information and therefore analysis possibilities that can be performed. In this case, the model is used to create Bode plots of the response of fluorescence to light oscillations and comparing these results to experimental data from \gls{chlamydomonas}.

This simple model stays true to its name and the authors aim to provide a base model that can be easily extended, while still showing a new approach to photosynthesis modelling. Their work shows that even with a simple model, new insights can be gained by using dynamic light protocols, which may have been overlooked in traditional steady-state models. To further extend the usability of the model, the authors provide a detailed notebook written in the Wolfram language, which also shows how to recreate some of the publication's figures.

\subsubsection{Li2021}

\subsubsection{Matuszynska2016}
The Matuszynska2016~\cite{matuszynskaMathematicalModelNonphotochemical2016} model, a small kinetic model, was developed to delve deeper into the effect of light memory caused by non-photochemical quenching. The systematic investigation of the Xanthophyll cycle, a combination of the pigments of violaxanthin, antheraxanthin, and zeaxanthin, sparked a series of experiments to determine whether plant light memory can be detected in a timescale of minutes to hours through pulse amplitude modulated chlorophyll fluorescence. The model was then created based on these experimental results, providing a comprehensive description of \gls{npq} dynamics and the short-term memory of the \gls{arabidopsis} plant.

To keep the model as simple as possible, several processes not directly linked to \gls{npq} have been simplified to create a dynamic ODE system consisting only of 6 different compounds. With these simplifications, the authors could fulfil an additional goal: to make a general framework that is not specific to one model organism.

To demonstrate the adaptability of their model, the authors took their calibrated \gls{arabidopsis} model and successfully applied it to the non-model organism \gls{epipremnum}. This adaptation allowed them to simulate realistic fluorescence measurements and replicate all the key features of chlorophyll induction, showcasing the model's versatility and potential for use in a variety of organisms.

\subsubsection{Saadat2021}
The Saadat2021~\cite{saadatComputationalAnalysisAlternative2021} model builds upon previous models, particularly the Matuszynska2019 model, by incorporating and modifying various reactions and aspects of photosynthesis. Overall, the model can be divided into three modules: the ascorbate-glutathione cycle, the \gls{cbb} cycle and thioredoxin reductase-regulated reactions, and the \gls{petc}.

The model is primarily used to investigate the electron flows around PSI and their relevance to photosynthetic efficiency. Several different analyses have been conducted to validate the model in both steady-state and dynamic environment conditions. The most interesting is the direct comparison of a knockout mutant of the protein PGR5. This protein is known to catalyse the reduction of plastoquinone by ferredoxin. The results of this comparison align with experimental values, which are, however, not presented in the publication but are referenced. Additionally, it is noted that the results should not be interpreted as accurate quantitative data, but rather as a proof of concept for the model.

Overall, the model has one advantage over other photosynthesis models, as it also highlights the importance of other electron flows, not just the \gls{petc}. Additionally, not only are the authors open about the model's flaws, but they are also insistent on making their code and analyses available on GitHub. Therefore, this model serves as a good stepping stone for more complex models that aim to incorporate aspects of photosynthesis, which are often simplified in other models.

\subsection{Model Demonstrations}\label{sec:model-demonstrations}

\subsubsection{Daylight Simulation}
The \gls{ppfd} data in a 1-minute resolution used for the daylight simulation demonstration is taken from \gls{neon} at the KONZ site, located in Kansas, USA (39.10077, -96.56307)~\cite{nationalecologicalobservatorynetworkneonPhotosyntheticallyActiveRadiation2023}, using the \verb|neonutilities| package~\cite{lunchNeonutilitiesPackageAccessing}. As only a day is shown in the simulation, only data from the 19th of June 2023 is taken into account. To limit the data to only the part of day that has sunlight, and a decent amount at that, the data is filtered to only include data that has a \gls{ppfd} value higher and equal than \qty{40}{\micro\mol\per\square\meter\per\second}. This threshold is chosen as it has shown to allow most models to still simulate the photosynthetic machinery, while still being a decent representation of the actual daylight conditions. The filtered data is then used as an input for the \gls{ppfd} parameter in the daylight simulation demonstration for every model. The protocol is constructed by simulating each point of \gls{ppfd} data for 60 seconds. Three different outputs are shown in this demonstration: the \gls{vc}, the \gls{atp} and \gls{nadph} ratio, and the \gls{F} yield. If these outputs are not available in the model at hand, the plot is still displayed with the corresponding y-axis label, struck through.

\subsubsection{FvCB Add-on}
The basis of the \gls{fvcb} add-on demonstration is based on the min-$W$ variant. If the supplied model already has a \gls{A}, then a generic FvCB simulation is done and compared to the results from von Caemmerer (2013)~\cite{voncaemmererSteadystateModelsPhotosynthesis2013}. If there is no available instance of \gls{A}, the two main and mandatory connection points for the add-on are the \gls{vc} and a quantity that represents \gls{co2}. If these two connection points are not available in the model, the simulation will not run, and only the general \gls{fvcb} output will be shown.

The \gls{vc} needs to be in a unit of \unit{\micro\mole\per\square\meter\per\second}. To convert from a concentration per time unit, the space that the stroma occupies in the chloroplast based on the leaf volume needs to be used. The value taken for this add-on was taken from Laisk et al. (2006)~\cite{laiskC3PhotosynthesisSilico2007}, where it was estimated and set to \qty{0.0112}{\liter\per\square\meter}.

As the \gls{fvcb} model requires a partial pressure of \gls{co2}, specifically the \gls{ci}, this quantity can also be given to the add-on if available in the model at hand. If it is not given, but the \gls{co2} is, a conversion using Henry's law is done to convert the concentration of \gls{co2} into a partial pressure. The default Henry's law constant used for this conversion is \qty{3.4e-5}{\milli\molar\per\micro\bar}~\cite{sanderCompilationHenrysLaw2023}, however, the law constant can also be supplied, when it is a part of the model.

With these two quantities given in the correct format, the \gls{fvcb} add-on can be added to any kinetic \gls{ode} model of photosynthesis. To finally create the representation of \gls{A}, the add-on includes the \gls{gammastar} and \gls{rlight}, \qty{38.6}{\micro\bar} and \qty{1}{\micro\mol\per\square\meter\per\second}, respectively, if not given by the model. With all of these quantities included in the model, the \gls{A} can be calculated~\cleverref[]{Equation}{eq:fvcb} and shown in the demonstration plot with a generic \gls{fvcb} simulation using parameters taken from von Caemmerer (2013)~\cite{voncaemmererSteadystateModelsPhotosynthesis2013}.

\begin{equation}
  \label{eq:fvcb}
  \glsxtrshort{A} = \glsxtrshort{vc} \cdot \left( 1 - \frac{\glsxtrshort{gammastar}}{\glsxtrshort{ci}} \right) - \glsxtrshort{rlight}
\end{equation}

\subsubsection{Standard PAM Simulation}
The standard \gls{pam} simulation demonstration uses a generic protocol that does not reflect actual experiments, but are in the same spirit as true experimental work. Prior to the actual protocol, the simulation of the model is done under dark conditions for \qty{30}{\min}. Then the actual protocol consists of 22 periods of a length of \qty{2}{min}, which start with the specific light intensity of that period and ends with a saturating pulse of \qty{3000}{\micro\mol\per\square\meter\per\second} for \qty{0.8}{\second}. The first two periods are in dark conditions, followed by 10 periods of actinic light of \qty{1000}{\micro\mol\per\square\meter\per\second} and finishes with 10 periods of dark conditions again. The dark condition is set to \qty{40}{\micro\mol\per\square\meter\per\second}, as it has been found that many models are not capable of simulating actual zero light conditions.

With this protocol, the simulation of the model is run and the \gls{F} and \gls{npq} is shown in the demonstration plot. If \gls{F} is not present in the model, the corresponding plot is still displayed with the y-axis label struck through. If \gls{npq} is not available, but \gls{F} is, it is calculated by using \gls{Fm}~\cleverref[]{Equation}{eq:npq}.
 
\begin{equation}
  \label{eq:npq}
  \glsxtrshort{npq}(t) = \frac{\glsxtrshort{Fm}(t=0) - \glsxtrshort{Fm}(t=t)}{\glsxtrshort{Fm}(t=t)}
\end{equation}

\gls{Fm} is extracted by using the simulated \gls{F} values at the time points where the saturating pulses are applied. To be sure that the actual \gls{Fm} is found, an interval between the two saturating pulses is taken, and the maximum value in that interval is used as \gls{Fm}. Most of the time this value is correct, but for full transparency, these values are plotted as triangles on the \gls{F} plot, additionally to the \gls{npq}.
\subsubsection{MCA of Photosynthesis}
The \gls{mca} demonstration limits its analysis to variables and fluxes that are deemed integral parts of photosynthesis. The variables to be given should account for a representation of \gls{pga}, \gls{rubp}, \gls{pq_ox}, \gls{pc_ox}, \gls{atp}, and \gls{nadph}. The rates should include the \gls{vc}, \gls{vpsii}, \gls{vpsi}, \gls{vb6f}, and \gls{vatp}. The parameters analyzed are supposed to be the control coefficients of each prior mentioned rate, and therefore the \gls{mca} simulations are run to steady-state. Each parameter is displaced by $\pm \ 0.01 \%$ and the results are put into two separate heatmaps, one for the variables and one for the fluxes. If any of the prior mentioned variables or rates are not available in the model, the corresponding row and column in the heatmaps are still displayed, but white and with less opacity.

\subsubsection{Fitting of NPQ}
The fitting demonstration uses experimental data taken from von Bismarck (2022)~\cite{vonbismarckLightAcclimationInteracts2023}. The data consists of measurements of \gls{F}, \gls{Fm}, and \gls{npq} calculated~\cleverref[]{Equation}{eq:npq} under different light intensities, following a \gls{pam} protocol after a dark adaptation period of \qty{5}{\min}. The data was taken with Maxi Imaging-PAM (Walz, Germany) using Col-0 \gls{arabidopsis} plants and as no details were given, the default settings of the machine are taken. That means, that each saturating pulse is \qty{5000}{\micro\mol\per\square\meter\per\second} for \qty{720}{\milli\second}. Each period consists of a simulation of a specific light intensity and finishes with a saturating pulse, together lasting approximately \qty{1}{\min}. There are four different sections during this \gls{pam} protocol. Starting with one dark period with a light intensity of \qty{0}{\micro\mol\per\square\meter\per\second}, followed by 10 high actinic light periods of \qty{903}{\micro\mol\per\square\meter\per\second} then dropping the actinic light to \qty{90}{\micro\mol\per\square\meter\per\second}, also for 10 periods, then again 5 dark periods to finish the protocol.

The protocol used for the simulation is based on the actual data provided. The difference of each timestamp recorded and the \gls{ppfd} value at that time is taken. With this simulation protocol, the fitting procedure can be created. The parameters to be fitted are given to the fitting routine with only a bound of zero. If the default value of the parameter is lower than zero, then that bound will be considered the upper bound, else it is set as the lower bound. With each variation of the parameters, the simulation is run with the prior mentioned protocol. If the model includes \gls{npq}, that output will be fitted to the experimental data. If \gls{npq} is not available, but \gls{F} is, then the \gls{F} output will be used to calculate the \gls{npq} using~\cleverref[]{Equation}{eq:npq} and then fitted to the experimental data. If neither are available, the fitting will not be done and the demonstration plot will only show the experimental data.

To actually fit the simulation output to the experimental data, the Levenberg-Marquardt method is used. This method is the most common and basic non-linear fitting algorithm, which is why it was chosen for this demonstration. On top of that, the standard scale method is implemented by default to help the fitting process. As the fitting is done using the \verb|Model| instance from the package \verb|lmfit|~\cite{newvilleLMFITNonLinearLeastSquares2025}, the inclusion of standard scaling is done by setting the \verb|weights| argument to the reciprocal fraction of the standard deviation of the experimental data and having both the \gls{npq} results of the experimental data and simulation results be centered around the mean of the data~\cleverref[]{Equation}{eq:lmfit-standard-scaling}. As sometimes no results for the simulation occurs depending on the parameter set, a large penalty value is returned to the fitting routine to avoid these parameter sets.

\begin{figure*}
  \begin{equation}
    \begin{alignedat}{2}
      \label{eq:lmfit-standard-scaling}
      \text{Standard Scale} &: x_\mathrm{new} &&= \frac{x_\mathrm{old} - \mu_\mathrm{data}}{\sigma_\mathrm{data}}\\
      \texttt{lmfit}\ \text{Calculation} &: \text{Residual} &&= \text{weights} \cdot \left( x_\mathrm{data} - x_\mathrm{model} \right)\\
      \text{Insert Standard Scale} &: \text{Residual} &&= \frac{1}{\sigma_\mathrm{data}} \cdot \left( \left(x_\mathrm{data|old} - \mu_\mathrm{data}\right) - \left(x_\mathrm{sim|old} - \mu_\mathrm{data}\right) \right)\\
    \end{alignedat}
  \end{equation}
\end{figure*}

After the best "possible" fit is found, according to the performed simulations, the results are plotted in the demonstration plot, showing both the experimental data points and the fitted simulation line. The \gls{F} and \gls{npq} are both shown separately for the experimental data and the best fit, and top of that a relative difference plot between the best fit or the original model parameter set is shown against the experimental data. To showcase the changes made in the fitting, a table of the changed parameters and their relative change is also displayed in the demonstration plot. The choosing of the parameters to be fitted is left to the user, as different models may have different parameters that influence \gls{npq} more than others.

\subsection{GreenSlothUtils}
The \greensloth[GreenSlothUtils] package, written in Python, contains several utility functions to assist in packaging an already written kinetic \gls{ode} model into a more code-readable and ready for uploading to the \greensloth{} website format. The functions included in this package vary in their complexity, from simple directory creation to rewriting model files. While \greensloth[GreenSlothUtils] has been written in a packge format, there is no intention to upload it to package sharing services such as PyPI. However, the package is intended to be used as a local package to assist in contribution to the \greensloth{} website, therefore the GitHub repository is publically available at \url{https://github.com/ElouenCorvest/GreenSlothUtils.git}.

\subsubsection{Documentation}

All the functions included in the package are documented in the GitHub repository, however some key functions are also documented below to showcase their utility in this project. This biggest upside of this package is the ability to quickly create a new model directory with all the necessary files and format for uploading to \greensloth{}. For ease of access, the functions required for this are combined inside a \gls{cli}.

Easily the most important part of the \gls{cli} of \greensloth[GreenSlothUtils] is the \verb|--help| command~\cleverref[]{Code-Block}{code:greenslothutils-help}, which gives an overview of all the possible commands and options available in the package. Each of the other commands also include a \verb|--help| option to give more specific information about the specific command.

\begin{figure*}
\begin{lstlisting}[style=bashstyle, caption={\textbf{The help command of the CLI of \greensloth[GreenSlothUtils]}}, label={code:greenslothutils-help}]
$ GreenSloth-init --help

Usage: GreenSloth-init [OPTIONS] COMMAND [ARGS]...

Options:
  --help  Show this message and exit.

Commands:
  compare-gloss-to-model    Compares glosses to model
  from-model-to-gloss       Generate temporary Glosses from model info.
  initialize                Create '<model-name>' directory.
  latex-from-model          Write LaTex from Model
  python-from-gloss         Write Python Variables from Glossaries
  update-glosses-from-main  Update glosses from main
\end{lstlisting}
\end{figure*}

Using these commands following a specific order allows for a quick and easy creation of a new model directory.

\emph{1. Create the directory}\\
First, the \verb|initialize| command is used to create a new and complete model directory with the correct name and structure~\cleverref[]{Code-Block}{code:greenslothutils-init}. One required argument is the name of the model, of which the directory should be named after. In the \greensloth{} ecosystem, the name of the model is the first author's last name followed by the year of publication, e.g., \texttt{Corvest2000}. This command also includes one optional argument, \verb|--path|, which allows the user to specify where the new model directory should be created. If no path is given, the directory is created in the current working directory. The directory created contains various different sub-directories and files, all pre-formatted to the \greensloth{} website standards~\cleverref[]{Directory Tree}{dir:greenslothutils-init}.

\begin{figure*}
\begin{lstlisting}[style=bashstyle, caption={\textbf{The initialize command of the CLI of \greensloth[GreenSlothUtils]}}, label={code:greenslothutils-init}]
$ GreenSloth-init initialize --help

Usage: GreenSloth-init initialize [OPTIONS] <model-name>

  Create '<model-name>' directory.

Options:
  -p, --path TEXT  Path to create model directory. Defaults to path here.
  --help           Show this message and exit.
\end{lstlisting}
\end{figure*}

\begin{figure}[ht]
    \centering
    \begin{minipage}{0.3\textwidth}
        \dirtree{%
              .1 Corvest2000/.
              .2 figures/.
              .3 demonstrations.ipynb.
              .3 paper\_figures.ipynb.
              .2 model/.
              .3 basic\_funcs.py.
              .3 derived\_quantities.py.
              .3 \_\_init\_\_.py.
              .3 rates.py.
              .2 model\_info/.
              .3 comps.csv.
              .3 derived\_comps.csv.
              .3 derived\_params.csv.
              .3 params.csv.
              .3 rates.csv.
              .2 README\_script.py.
          }
    \end{minipage}
    \captionof{dirset}{\textbf{Example directory structure created by the \texttt{initialize} command of \greensloth[GreenSlothUtils].}}
    \label{dir:greenslothutils-init}
\end{figure}


The \verb|figures| directory consists of two Jupyter Notebooks. The \verb|demonstrations.ipynb| includes all Model Demonstrations for the model, already written out, with each demonstration having its own cell. The creator of the model simply has to replace the \verb|None| values of each string representation of model parts needed for the demonstration. For more information on what the demonstrations entail, please refer to \hyperref[sec:model-demonstrations]{Section \ref*{sec:model-demonstrations}}. The \verb|paper_figures.ipynb| is a blank notebook intended to be used to recreate the figures of the model's publication. Both notebooks already include necessary imports and helper functions to quickly get started. If the model is correctly implemented inside the \verb|model| directory, the importing of the model should work.

The \verb|model| directory consists of the actual \gls{ode} model implementation in Python. For ease of use, the \greensloth{} ecosystem sets using the \verb|mxlpy|~\cite{vanaalstMxlPyPythonPackage2025} package as a standard for writing kinetic \gls{ode} models in Python. This has been chosen due to its ease of use, speed, and continuous support from the maintainers. The most important file of the \verb|model| directory is the \verb|__init__.py| file, which contains the main model initialization. As a strong recommendation, the actual parts of the model, such as the rates, basic functions, and derived quantities, should be written in separate files, as shown in \hyperref[dir:greenslothutils-init]{Directory Tree \ref*{dir:greenslothutils-init}}. This allows for better code readability and easier debugging. To help with formatting a model written using \verb|mxlpy|, the \greensloth[GreenSlothUtils] package contains a subpackage, \verb|GreenSlothUtils.mxlpy_formatter|, which contains several functions to assist in rewriting a model into the correct format for \greensloth{}.

The \verb|model_info| directory contains all the necessary information about the model in a \verb|.csv| format. This includes the variables, parameters, derived variables and parameters, and rates of the model. Each of these files follow a specific format, where a short description, the mathematical depiction in the publication and in \greensloth{}, and the variable used in Python code. Additionally, the variables and rates also include a column of \gls{kegg} IDs and Glossary Indices to assist in linking the model to existing databases and the \greensloth{} overarching glossary. The parameters, on the other hand, also include a column for units, values and sources given in the publication. These \verb|.csv| files are used to automatically generate the glossary entries of the model when uploading to the \greensloth{} website, therefore it is important that they are correctly filled out. To assist in this process, functions have been created, that extract the valuable information from an existing model implementation in \verb|mxlpy| into the tables, already separating them into the correct columns. But more on those functions later.

Finally, the \verb|README_script.py| file is a template script intended to be used to write the model's README file for the \greensloth{} website and in general the model's documentation. This script includes several prefilled sections, such as tables extracted from the prior mentioned \verb|model_info| directory, a generic installation guide, and the assumptions and brief description of the model demonstrations. The user simply has to fill in the specific details of the model, such as a short summary, \LaTeX{} version of the equations used, the recreation of the publication figures, and notes to the demonstrations. Writing the README in this Python script format allows for easier accessing of repeating information, such as specific variables or parameters, without having to manually find them and replace them in a written Markdown file. Make a few changes in the script, run it, and the README file is ready to go.

\emph{2. Extract Information from the Model}\\
Once the directory is created and the model is completely implemented, the next step is to extract necessary information from the model into the \verb|model_info| tables. This is done using several commands of the \greensloth[GreenSlothUtils] \gls{cli}.

The \verb|from-model-to-gloss| function extracts all the necessary information from an \verb|mxlpy| model into temporary Glossaries as a \verb|.csv| format~\cleverref[]{Code-Block}{code:greenslothutils-from-model-to-gloss}. The options \verb|--model-dir|, \verb|--modelinfo-dir|, and \verb|--modelgloss-dir| allow the user to specify where the model is located, where the model info tables are located, and where to store the generated Glosses, respectively. If no paths are given, the function assumes that the model directory is in the current working directory, the model info directory is in the model directory under \verb|model_info/|, and the generated Glosses should be stored in a new directory called \verb|model_glosses/| inside the \verb|model_info/| directory. The option \verb|--extract-option| allows the user to specify which parts of the model should be extracted. The possibilities are \texttt{all}, \texttt{variables}, \texttt{parameters}, \texttt{derived\_variables}, \texttt{derived\_parameters}, and \texttt{reactions}. By default, all parts are extracted. Finally, the \verb|--check| option allows the user to check for inconsistencies between the generated Glossaries and the existing model info tables using the \verb|compare-gloss-to-model| command. It is recommended to point the terminal inside the overarching directory of the model and run the command with the default values. This is the easiest way to ensure that all paths are correctly set and still follow the custom directory structure of the \greensloth{}~\hyperref[dir:greenslothutils-init]{Directory Tree \ref*{dir:greenslothutils-init}}. With the automatic extraction of the model information filling out the actual \verb|model_info| tables is made significantly easier. The user can then be on the safe side, that no variables, parameters, or rates have been forgotten. However, only the python variable is extracted and the other columns still have to be filled out manually by the user.

\begin{figure*}
\begin{lstlisting}[style=bashstyle, caption={\textbf{The from-model-to-gloss command of the CLI of \greensloth[GreenSlothUtils]}}, label={code:greenslothutils-from-model-to-gloss}]
$ GreenSloth-init from-model-to-gloss --help

Usage: GreenSloth-init from-model-to-gloss [OPTIONS]

  Generate temporary Glosses from model info.

Options:
  -md, --model-dir TEXT        Path to model directory. Defaults to path here
  -mid, --modelinfo-dir TEXT   Path to model info directory. Defaults to
                               model-dir + 'model_info'
  -mgd, --modelgloss-dir TEXT  Path to where to store csvs. Defaults to model-
                               dir + 'model_info/model_glosses/'
  -eo, --extract-option TEXT   Parts of the model to extract. Possibilities:
                                  'all',
                                  'variables',
                                  'parameters',
                                  'derived_variables',
                                  'derived_parameters',
                                  'reactions',
                                  [default: 'all']
  --check / --no-check         Check for inconsistencies with
                               'compare_gloss_to_model'
  --help                       Show this message and exit.
\end{lstlisting}
\end{figure*}

To create a bridge between the different models, overarching glossaries for the variables and rates have been created in the \greensloth{} ecosystem. With access to these glossaries, only the ID associated to that variable or rate has to be included in the model info tables, and the rest of the information is automatically filled out using the \verb|update-glosses-from-main| command~\cleverref[]{Code-Block}{code:greenslothutils-update-glosses-from-main}. This command updates the existing model info tables with information from the main glossaries, such as the description, \gls{kegg} ID, and mathematical depiction in \greensloth{}. The options \verb|--model-dir|, \verb|--modelinfo-dir|, and \verb|--maingloss-dir| allow the user to specify where the model is located, where the model info tables are located, and where the main glossaries are located, respectively. If no paths are given, the function assumes that the model directory is in the current working directory, the model info directory is in the model directory under \verb|model_info/|, and the main glossaries are in the parent directory of the current working directory. The \verb|--add| option allows the user to add new entries to the main glossary if they do not already exist. By default, this option is set to \verb|False|. Again, it is recommended to point the terminal inside the overarching directory of the model and run the command with the default values. This is the easiest way to ensure that all paths are correctly set and still follow the custom directory structure of the \greensloth{}~\hyperref[dir:greenslothutils-init]{Directory Tree \ref*{dir:greenslothutils-init}}. If the model includes variables and rates that are not in the main glossaries, this command can also add them automatically, subsequently adding a new ID. While this is a very handy feature, it is recommended to critically evaluate the new entries before running \verb|update-glosses-from-main| with the \verb|--add| option, to ensure that no duplicate or incorrect entries are added to the main glossaries.

\begin{figure*}
\begin{lstlisting}[style=bashstyle, caption={\textbf{The update-glosses-from-main command of the CLI of \greensloth[GreenSlothUtils]}}, label={code:greenslothutils-update-glosses-from-main}]
$ GreenSloth-init update-glosses-from-main --help

Usage: GreenSloth-init update-glosses-from-main [OPTIONS]

  Update glosses from main

Options:
  -magd, --maingloss-dir TEXT  Path to directory with main gloss. Defaults to
                               parent of here.
  -md, --model-dir TEXT        Path to model directory. Defaults to path here
  -mid, --modelinfo-dir TEXT   Path to model info directory. Defaults to
                               model-dir + 'model_info'
  --add / --no-add             Add new entries to main gloss. Defaults to
                               False.
  --help                       Show this message and exit.

\end{lstlisting}
\end{figure*}

Once the information has been added to the model info tables, the \LaTeX{} depiction of each piece of the model will act as the main liaison between the info tables and the subsequent model documentation, as these depictions will not change. The rest of the information may always need to be changed due to updates to the naming convention or other problems.

\emph{3. Correct the Model}\\
After updating the model info tables from the main glossaries or deciding on a different name for something, it is vital to ensure the \verb|mxlpy| model implementation still holds the same information. For that, \greensloth[GreenSlothUtils] includes the \verb|compare-gloss-to-model|, which is already implemented in the \verb|from-model-to-gloss| command as the \verb|--check| option~\cleverref[]{Code-Block}{code:greenslothutils-from-model-to-gloss}. This command compares the existing model info tables to the actual \verb|mxlpy| model implementation, checking for inconsistencies in variable names, parameter names, and rate names. If any inconsistencies are found, they are printed in the terminal, allowing the user to quickly find and correct them in the model implementation. This step is crucial to ensure that the model implementation and the model info tables are in sync, as correct documentation is a key aspect of the \greensloth{} ecosystem. It has to be noted, that the category of derived variables and parameters is separated by using the logic of \verb|mxlpy|, meaning that if something is derived from at least one variable it is classified as a derived variable, and something that is only derived from parameters is a derived parameter. Therefore, if the user manually wishes to change the category of a derived quantity, they may do so in the model info tables, but have to remember, that the \verb|compare-gloss-to-model| command will not check for inconsistencies in this regard.

\emph{4. Create Pointer to Python Variables}\\
Once the model info tables and the model implementation are done, the documentation of the model can be tackled. One big feature that is important to \greensloth{} is consistency. To ensure that all the variables, parameters, and rates mentioned in the documentation are consistent along the entire documentation file, a pointer in the \verb|README_script.py| file can be created. To do this easily, the \verb|python-from-gloss| command of \greensloth[GreenSlothUtils] can be used~\cleverref[]{Code-Block}{code:greenslothutils-python-from-gloss}. This command creates Python variable assignments for all the variables, parameters, derived quantities, and rates in the model info tables, and writes them in separated \verb|.txt| files. On top of that, these files are also managed as a log and shows the last update done with \verb|python-from-gloss|. The options \verb|--model-dir| and \verb|--modelinfo-dir| allow the user to specify where the model and where the model info tables are located, respectively. If no paths are given, the function assumes that the model directory is in the current working directory and the model info directory is in the \verb|model_info/| directory. The option \verb|--glosstopython-dir| allows the user to specify where to store the generated Python variables. By default, this is set to the \verb|python_written/gloss_to_python| directory in the path given to \verb|--modelinfo-dir|. Once again, it is recommended to point the terminal inside the overarching directory of the model and run the command with the default values. This is the easiest way to ensure that all paths are correctly set and still follow the custom directory structure of the \greensloth{}~\hyperref[dir:greenslothutils-init]{Directory Tree \ref*{dir:greenslothutils-init}}.

Once this command is run, the user can simply copy over the generated Python variable assignments into the \verb|README_script.py| file, creating a direct pointer to the actual variables used in the model info tables. This ensures that any changes made to the variable names in the model info tables are automatically reflected in the documentation, maintaining consistency throughout. This last step of manual copying is to ensure that the user critically evaluates the changes they have made and with the log feature, shows the last update.

\begin{figure*}
\begin{lstlisting}[style=bashstyle, caption={\textbf{The python-from-gloss command of the CLI of \greensloth[GreenSlothUtils]}}, label={code:greenslothutils-python-from-gloss}]
$ GreenSloth-init python-from-gloss --help

Usage: GreenSloth-init python-from-gloss [OPTIONS]

  Write Python Variables from Glossaries

Options:
  -md, --model-dir TEXT           Path to model directory. Defaults to path
                                  here
  -mid, --modelinfo-dir TEXT      Path to model info directory. Defaults to
                                  -md + 'model_info'
  -gpd, --glosstopython-dir TEXT  Path to gloss to python directory. Defaults
                                  to -mid + 'python_written/gloss_to_python'
  --help                          Show this message and exit.

\end{lstlisting}
\end{figure*}

\emph{5. Generate \LaTeX{} equations}\\
A big part of kinetic \gls{ode} model documentation is the correct depiction of the equations used in the implementation. To assist in this process, the \verb|latex-from-model| command of \greensloth[GreenSlothUtils] can be used to automatically generate \LaTeX{} equations from the \verb|mxlpy| model implementation~\cleverref[]{Code-Block}{code:greenslothutils-latex-from-model}. This command extracts the mathematical depictions of the variables, parameters, derived quantities, and rates from the \verb|mxlpy| model and writes them in a \verb|.txt| file. The options \verb|--model-dir| and \verb|--modelinfo-dir| allow the user to specify where the model is located and where the model info tables are located, respectively. If no paths are given, the function assumes that the model directory is in the current working directory and the model info directory is the \verb|model_info/| directory. The option \verb|-- modeltolatex - dir| allows the user to specify where to store the generated \LaTeX{} equations. By default, this is set to the \verb| python_written / model_to_latex | directory in the path given to \verb|--modelinfo-dir|. Once again, it is recommended to point the terminal inside the overarching directory of the model and run the command with the default values. This is the easiest way to ensure that all paths are correctly set and still follow the custom directory structure of the \greensloth{}~\hyperref[dir:greenslothutils-init]{Directory Tree \ref*{dir:greenslothutils-init}}. To generate the \LaTeX{} equations, \greensloth[GreenSlothUtils] uses the \verb|latexify| package~\cite{LatexifypyGeneratesLaTeX}, which is specifically designed to extract \LaTeX{} equations from Python functions. However, sometimes the python functions are too complex for \verb|latexify| to handle, therefore it is recommended to critically evaluate the generated \LaTeX{} equations before using them in the documentation. Once generated, the user can simply copy over the \LaTeX{} equations into the correct sections of the \verb|README_script.py| file, taking note, that the equations already include the python variable names used in the pointer created in the previous step.

\begin{figure*}
\begin{lstlisting}[style=bashstyle, caption={\textbf{The latex-from-model command of the CLI of \greensloth[GreenSlothUtils]}}, label={code:greenslothutils-latex-from-model}]
$ GreenSloth-init latex-from-model --help

Usage: GreenSloth-init latex-from-model [OPTIONS]

  Write LaTex from Model

Options:
  -md, --model-dir TEXT          Path to model directory. Defaults to path
                                 here
  -mid, --modelinfo-dir TEXT     Path to model info directory. Defaults to -md
                                 + 'model_info'
  -mld, --modeltolatex-dir TEXT  Path to model to latex directory. Defaults to
                                 -mid + 'python_written/model_to_latex'
  --help                         Show this message and exit.

\end{lstlisting}
\end{figure*}

\emph{6. Recreate the Publication figures}\\
To validate the recreation of the \verb|mxlpy| model implementation, it is important to recreate the figures of the original publication. Sadly, this step cannot be automated by \greensloth[GreenSlothUtils], as the figures vary significantly between different models. However, the \verb|paper_figures.ipynb| notebook included in the \verb|figures/| directory of the model structure~\cleverref[]{Directory Tree}{dir:greenslothutils-init} is intended to be used for this purpose. The user simply has to fill in the necessary code to recreate the figures, using the implemented \verb|mxlpy| model. It is recommended to create a \verb|str| dictionary at the top of the Notebook, that consists of the string representations of the different parts of the model, needed for the simulations. This allows for easier changing of variables and parameters, without having to search through the entire Notebook for the correct strings. Once the figures are recreated, a template in the \verb|README_script.py| file is already included to integrate the generated figures into the documentation. Additionally, a brief description on how this figure was created and a short analysis on the recreation process is needed. A rule of thumb for the caption of a simulation figure, is to include as many details that are needed to recreate the simulation done in the figure, without having to refer back to the code. This rule of thumb is often missing in scientific publications, which is why some figures may be hard or even impossible to recreate. If that is the case in the model at hand, it is recommended to still include a brief note on what was missing to recreate the figure, to ensure full transparency. As this section is supposed to represent a comparison of the figures of the original publication and the \verb|mxlpy| model implementation, showing the figures side by side would be ideal, however, due to possible copyright issues, it is best to only refer the reader to the publication for the original figures.

\emph{7. Create the Demonstrations}\\
The last step in the documentation process is to fill out the \verb|demonstrations.ipynb| Notebook included in the \verb|figures/| directory of the model structure~\cleverref[]{Directory Tree}{dir:greenslothutils-init}. This Notebook already includes all the necessary code to run the model demonstrations described in \hyperref[sec:model-demonstrations]{Section \ref*{sec:model-demonstrations}}. The user simply has to fill in the string representations of the different parts of the model needed for each demonstration. Some demonstrations may need specific pre-work done beforehand, but more details can be found in \hyperref[sec:model-demonstrations]{Section \ref*{sec:model-demonstrations}} and the documentation of \greensloth[GreenSlothUtils]. Once the demonstrations are filled out, a brief description of each demonstration is already included in the \verb|README_script.py| file, where the user simply has to fill in a brief analyses of the demonstration, including how it looks and if something did not work, why.

\emph{8. Finishing touches}\\
As the \verb|README_script.py| is now filled out with all the necessary information, the last step is to run the script to generate the final \verb|README.md| file for the model. It is recommended to critically evaluate the generated README file for any mistakes or inconsistencies, especially in the regard of any \LaTeX{} representations, as errors in these are very prone to happen. Once the README file is finalised, the model is ready to be included on the \greensloth{} website.

\subsection{Website}

\subsection{Additional Methods}

\subsubsection{Usage of AI}
To stay completely transparent during this thesis, it has to be noted that several \gls{ai} tools have been used to assist in the code writing, documentation, and text writing process. Several \glspl{llm} have been used, including Gemini (Google) to help with finding models, ideas and writing code snippets for visualisation. Additionally, GitHub Copilot has been used to assist in code writing, mainly to streamline the writing and debugging process. The exact parts of this thesis that have been assisted by \gls{ai} tools cannot be exactly determined, as the suggestions are mainly used to inspire and speed up the writing process. However, every part of this thesis has been critically evaluated and edited by the author to ensure accuracy and quality.